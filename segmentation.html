

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Segmentation &#8212; Fundamental Tools for Image Processing</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/jbvinc.css" />
    <link rel="stylesheet" type="text/css" href="_static/.ipynb_checkpoints/jbvinc-checkpoint.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-index--0afa1ebdab0bb23b98b56d34c23d9f57.css" />
    <link rel="stylesheet" type="text/css" href="_static/spanels-variables--ffc7f74dcb1b9eecba2dbcbc22818714.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Deconvolution" href="deconvolution.html" />
    <link rel="prev" title="Registration" href="registration.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Fundamental Tools for Image Processing</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   Preface
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Courses
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="definition.html">
   What is a Digital Image?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="operations.html">
   Arithmetic Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="histogram.html">
   Histogram
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convolution.html">
   Convolution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fourier.html">
   Fourier Transform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="compression.html">
   Compression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mm.html">
   Mathematical Morphology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interpolation.html">
   Interpolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="registration.html">
   Registration
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="deconvolution.html">
   Deconvolution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="denoising.html">
   Denoising
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="xxx_pattern.html">
   (Pattern &amp; Co)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  In-Class Sessions
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="tp1.html">
   07/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tp2.html">
   14/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tp3.html">
   21/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tp4.html">
   04/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tp5.html">
   18/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tp6.html">
   25/11/2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Corrections
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp1-code.html">
   07/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp2-code.html">
   14/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp3-code.html">
   21/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp4-code.html">
   04/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp5-code.html">
   18/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="labs/tp6-code.html">
   25/10/2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://moodle3.unistra.fr/course/view.php?id=13708">
   Moodle
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python.html">
   Installing and Using Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="biblio.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="license.html">
   License
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/segmentation.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#histogram-thresholding">
   Histogram thresholding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binarisation">
     Binarisation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#methode-de-otsu">
     Méthode de Otsu
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seuillage-multiple">
     Seuillage multiple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification">
   Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithme-des-k-moyennes">
     Algorithme des k-moyennes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#region-based-methods">
   Region-based methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#croissance-de-region">
     Croissance de région
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decomposition-fusion">
     Décomposition/fusion
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#watershed">
   Watershed
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-evaluate-the-segmentation">
   How to evaluate the segmentation?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="segmentation">
<span id="c-segmentation"></span><h1>Segmentation<a class="headerlink" href="#segmentation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>La segmentation consiste à partitionner une image <span class="math notranslate nohighlight">\(f\)</span> selon un <em>critère d’homogénéité</em>.
« Partitionner » signifie que l’image est divisée en plusieurs régions <span class="math notranslate nohighlight">\(R_i\)</span>
qui sont à la fois disjointes et telles que l’ensemble de ces régions recouvrent l’intégralité de l’image.
Les pixels d’une région vérifient le critère d’homogénéité,
mais les pixels de deux régions adjacentes ne le vérifient pas.</p>
<p>Les figures ci-après présentent plusieurs exemples de segmentation.</p>
<div class="figure align-default" id="f-segmentation-examples">
<a class="reference internal image-reference" href="_images/segmentation-examples.png"><img alt="_images/segmentation-examples.png" src="_images/segmentation-examples.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 48 </span><span class="caption-text">Exemples de segmentation.</span><a class="headerlink" href="#f-segmentation-examples" title="Permalink to this image">¶</a></p>
</div>
<p>Ce chapitre présente plusieurs méthodes de segmentation,
et termine sur la façon de mesurer la qualité de la segmentation.
Mais avant tout, il est utile de définir quelques termes liés à la relation qui peut exister entre les pixels.</p>
<p><strong>Connexité</strong></p>
<p>La connexité est la façon dont sont définis les voisins d’un pixel.
En général, on n’utilise que l’une des deux connexités suivantes :</p>
<ul class="simple">
<li><p>la 4-connexité : un pixel possède quatre voisins (en haut, en bas, à gauche, à droite),</p></li>
<li><p>la 8-connexité : un pixel possède huit voisins (les quatre précédents et ceux sur les diagonales).</p></li>
</ul>
<div class="figure align-default" id="f-segmentation-connexity">
<a class="reference internal image-reference" href="_images/connexity.png"><img alt="_images/connexity.png" src="_images/connexity.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 49 </span><span class="caption-text">4-connexité (à gauche) et 8-connexité (à droite). Les pixels en gris sont les voisins du pixel <span class="math notranslate nohighlight">\((m,n)\)</span>.</span><a class="headerlink" href="#f-segmentation-connexity" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Composante connexe</strong></p>
<p>Une composante connexe (<em>connected component</em>) est un groupe de pixels
tel qu’on puisse aller d’un pixel de ce groupe à un autre pixel de ce groupe
en passant par des pixels du même groupe voisins entre eux.</p>
<p>Ainsi, dans la <a class="reference internal" href="#f-segmentation-connected-component"><span class="std std-numref">Fig. 50</span></a>,
le nombre de composantes connexes est égal à 5 si on considère un voisinage en 4-connexité,
ou à 4 si on considère un voisinage en 8-connexité.</p>
<div class="figure align-default" id="f-segmentation-connected-component">
<a class="reference internal image-reference" href="_images/connected-component.png"><img alt="_images/connected-component.png" src="_images/connected-component.png" style="height: 150px;" /></a>
<p class="caption"><span class="caption-number">Fig. 50 </span><span class="caption-text">Le nombre de composantes connexes (entourées d’un trait de couleur) dépend de la connexité considérée.</span><a class="headerlink" href="#f-segmentation-connected-component" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Remarques</strong></p>
<ul>
<li><p>Chaque région <span class="math notranslate nohighlight">\(R_i\)</span> de la segmentation est une composante connexe.</p></li>
<li><p>Le résultat de la segmentation n’est pas unique :
il dépend du critère d’homogénéité choisi, de la méthode de segmentation utilisée, de l’initialisation, etc.</p></li>
<li><p>Une segmentation peut s’interpréter comme un graphe,
dans lequel les nœuds correspondent aux régions <span class="math notranslate nohighlight">\(R_i\)</span> et les liens représentent l’adjacence entre régions voisines.</p>
<div class="figure align-default" id="f-segmentation-connected-component-graph">
<a class="reference internal image-reference" href="_images/connected-component-graph.png"><img alt="_images/connected-component-graph.png" src="_images/connected-component-graph.png" style="height: 150px;" /></a>
<p class="caption"><span class="caption-number">Fig. 51 </span><span class="caption-text">Exemple de segmentation et son graphe associé.</span><a class="headerlink" href="#f-segmentation-connected-component-graph" title="Permalink to this image">¶</a></p>
</div>
</li>
</ul>
</div>
<div class="section" id="histogram-thresholding">
<h2>Histogram thresholding<a class="headerlink" href="#histogram-thresholding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="binarisation">
<h3>Binarisation<a class="headerlink" href="#binarisation" title="Permalink to this headline">¶</a></h3>
<p>Une méthode très simple de segmentation consiste à associer à chaque pixel de l’image <span class="math notranslate nohighlight">\(f\)</span>
une valeur binaire qui dépend de l’intensité des pixels et d’un seuil <span class="math notranslate nohighlight">\(T\)</span> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  g(m,n) =
  \begin{cases}
    1 &amp; \text{si}\, f(m,n)\geqslant T, \\
    0 &amp; \text{si}\, f(m,n)&lt; T
  \end{cases}
\end{split}\]</div>
<p>Cette méthode, appelée « binarisation », effectue une segmentation en deux classes
à partir de l’intensité des pixels d’une image à niveau de gris (cf. <a class="reference internal" href="#f-segmentation-binarize"><span class="std std-numref">Fig. 52</span></a>).</p>
<div class="figure align-default" id="f-segmentation-binarize">
<a class="reference internal image-reference" href="_images/segmentation-binarize.png"><img alt="_images/segmentation-binarize.png" src="_images/segmentation-binarize.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 52 </span><span class="caption-text">Exemple de binarisation d’une image de bactéries.</span><a class="headerlink" href="#f-segmentation-binarize" title="Permalink to this image">¶</a></p>
</div>
<p>Le résultat de la segmentation dépend de <span class="math notranslate nohighlight">\(T\)</span>, comme on le voit <a class="reference internal" href="#f-segmentation-threshold1"><span class="std std-numref">Fig. 53</span></a>.</p>
<div class="figure align-default" id="f-segmentation-threshold1">
<a class="reference internal image-reference" href="_images/segmentation-threshold1.png"><img alt="_images/segmentation-threshold1.png" src="_images/segmentation-threshold1.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 53 </span><span class="caption-text">Résultat de la segmentation en fonction du choix du seuil.</span><a class="headerlink" href="#f-segmentation-threshold1" title="Permalink to this image">¶</a></p>
</div>
<p>L’histogramme s’avère être un outil intéressant pour le choix du seuil.
Dans l’exemple illustré <a class="reference internal" href="#f-segmentation-threshold2"><span class="std std-numref">Fig. 54</span></a>, le choix du seuil est facile à partir de l’histogramme :
il suffit de choisir <span class="math notranslate nohighlight">\(T\)</span> entre les deux modes de ce dernier.</p>
<div class="figure align-default" id="f-segmentation-threshold2">
<a class="reference internal image-reference" href="_images/segmentation-threshold2.png"><img alt="_images/segmentation-threshold2.png" src="_images/segmentation-threshold2.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 54 </span><span class="caption-text">Segmentation binaire avec un seuil choisi par rapport à l’histogramme.</span><a class="headerlink" href="#f-segmentation-threshold2" title="Permalink to this image">¶</a></p>
</div>
<p>Mais dans d’autres cas, le choix du seuil est moins évident,
comme c’est le cas <a class="reference internal" href="#f-segmentation-threshold3"><span class="std std-numref">Fig. 55</span></a>
(il faut alors choisir un seuil comme dans la <a class="reference internal" href="#f-segmentation-threshold4"><span class="std std-numref">Fig. 56</span></a>).</p>
<div class="figure align-default" id="f-segmentation-threshold3">
<a class="reference internal image-reference" href="_images/segmentation-threshold3.png"><img alt="_images/segmentation-threshold3.png" src="_images/segmentation-threshold3.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 55 </span><span class="caption-text">Segmentation binaire avec un seuil choisi par rapport à l’histogramme.</span><a class="headerlink" href="#f-segmentation-threshold3" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="f-segmentation-threshold4">
<a class="reference internal image-reference" href="_images/segmentation-threshold4.png"><img alt="_images/segmentation-threshold4.png" src="_images/segmentation-threshold4.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 56 </span><span class="caption-text">Segmentation binaire avec un seuil choisi par rapport à l’histogramme.</span><a class="headerlink" href="#f-segmentation-threshold4" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="methode-de-otsu">
<h3>Méthode de Otsu<a class="headerlink" href="#methode-de-otsu" title="Permalink to this headline">¶</a></h3>
<p>La méthode de Otsu (1979) permet de déterminer le seuil <span class="math notranslate nohighlight">\(T\)</span> qui minimise la « variance intra-classe » <span class="math notranslate nohighlight">\(\sigma_w^2(T)\)</span>.
Cette variance intra-classe est la moyenne pondérée des variances <span class="math notranslate nohighlight">\(\sigma_1\)</span> et <span class="math notranslate nohighlight">\(\sigma_2\)</span> de chaque classe
(les classes étant les parties de l’histogramme délimitées par <span class="math notranslate nohighlight">\(T\)</span>, comme illustré <a class="reference internal" href="#f-segmentation-celine20"><span class="std std-numref">Fig. 57</span></a>):</p>
<div class="math notranslate nohighlight">
\[
  T = \arg \min_T \sigma_w^2(T) = \arg \min_T q_1(T)\sigma_1^2(T) + q_2(T)\sigma_2^2(T)
\]</div>
<div class="figure align-default" id="f-segmentation-celine20">
<a class="reference internal image-reference" href="_images/celine20.png"><img alt="_images/celine20.png" src="_images/celine20.png" style="height: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 57 </span><span class="caption-text">Notations utilisées.</span><a class="headerlink" href="#f-segmentation-celine20" title="Permalink to this image">¶</a></p>
</div>
<p>En considérant que les intensités <span class="math notranslate nohighlight">\(i\)</span> sont à valeurs dans <span class="math notranslate nohighlight">\(\{0,...,L-1\}\)</span>
et que <span class="math notranslate nohighlight">\(h\)</span> est l’histogramme de l’image, on a formellement :</p>
<ul class="simple">
<li><p>Pour la classe 1 :</p>
<ul>
<li><p>Proportion :    <span class="math notranslate nohighlight">\(\displaystyle q_1(T) = \frac{1}{MN} \sum_{i = 0}^{T} h(i)\)</span></p></li>
<li><p>Moyenne :       <span class="math notranslate nohighlight">\(\displaystyle m_1(T) = \frac{1}{MN}\frac{1}{q_1(T)} \sum_{i = 0}^{T} i h(i)\)</span></p></li>
<li><p>Variance :      <span class="math notranslate nohighlight">\(\displaystyle \sigma^2_1(T) = \frac{1}{MN}\frac{1}{q_1(T)} \sum_{i = 0}^{T}(i\!-\!m_1(T))^2 h(i)\)</span></p></li>
</ul>
</li>
<li><p>Pour la classe 2 :</p>
<ul>
<li><p>Proportion :    <span class="math notranslate nohighlight">\(\displaystyle q_2(T) = \frac{1}{MN}\sum_{i = T+1}^{L-1} h(i)\)</span></p></li>
<li><p>Moyenne :       <span class="math notranslate nohighlight">\(\displaystyle m_2(T) = \frac{1}{MN}\frac{1}{q_2(T)} \sum_{i = T+1}^{L-1} i g(i)\)</span></p></li>
<li><p>Variance :      <span class="math notranslate nohighlight">\(\displaystyle \sigma^2_2(T) = \frac{1}{MN}\frac{1}{q_2(T)} \sum_{i = T+1}^{L-1}(i\!-\!m_2(T))^2 h(i)\)</span></p></li>
</ul>
</li>
</ul>
<p>L’algorithme est simple : il suffit de calculer la variance intra-classe <span class="math notranslate nohighlight">\(\sigma_w^2(T)\)</span> pour tous les seuils <span class="math notranslate nohighlight">\(T = \{0,...,L-1\}\)</span>,
et de retenir finalement le seuil <span class="math notranslate nohighlight">\(T\)</span> qui minimise <span class="math notranslate nohighlight">\(\sigma_w^2(T)\)</span>.</p>
<p>Par ailleurs, remarquez que la variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> des intensités de l’image s’écrit :</p>
<div class="math notranslate nohighlight">
\[
  \sigma^2 = \sigma_w^2 + \sigma_{1,2}^2
\]</div>
<p>où <span class="math notranslate nohighlight">\(\sigma_{1,2}^2\)</span> est la « variance inter-classe » (variance pondérée des moyennes de chaque classe).
Ainsi, minimiser la variance intra-classe <span class="math notranslate nohighlight">\(\sigma_w^2\)</span> est équivalent à maximiser la variance inter classe <span class="math notranslate nohighlight">\(\sigma_{1,2}^2\)</span>
(puisque <span class="math notranslate nohighlight">\(\sigma^2\)</span> reste constant).
Cela signifie que construire deux groupes de pixels qui se ressemblent
revient à construire deux groupes de pixels très dissemblables.</p>
</div>
<div class="section" id="seuillage-multiple">
<h3>Seuillage multiple<a class="headerlink" href="#seuillage-multiple" title="Permalink to this headline">¶</a></h3>
<p>Lorsque plusieurs modes sont visibles sur l’histogramme,
il est possible d’utiliser plusieurs seuils pour aboutir à plusieurs classes :</p>
<div class="figure align-default" id="f-segmentation-multiple-thresholds">
<a class="reference internal image-reference" href="_images/segmentation-multiple-thresholds.png"><img alt="_images/segmentation-multiple-thresholds.png" src="_images/segmentation-multiple-thresholds.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 58 </span><span class="caption-text">Seuillage multiple.</span><a class="headerlink" href="#f-segmentation-multiple-thresholds" title="Permalink to this image">¶</a></p>
</div>
<p>En particulier, la méthode de Otsu peut être étendue à plusieurs seuils,
mais la complexité calculatoire augmente grandement avec le nombre de classes !</p>
<!-- La variation d'illumination ne permet pas de seuiller correctement l'image. Plusieurs solutions sont possibles.
TODO : afficher :
- image originale + son histogramme + son seuillage
- fond
- image sans fond + son histogramme + son seuillage
[image : seuillage_variation_illumination, \imgref{Gonzalez $\&$ Woods}

Éclairage $g$ connu : on utilise un modèle paramétrique pour le décrire et on corrige l'image avant le seuillage :
$$
\forall (m,n), \quad  h(m,n) = \frac{f(m,n)}{g(m,n)}
$$
* Éclairage $g$ inconnu : seuillage local par exemple
  \includegraphics[width=8.5cm]{seuillage_bloc}
  \imgref{Gonzalez $\&$ Woods}
\pnode(3.8,1.2){A}
\rput[lt](2,0.3){\rnode{B}Attention : zone à une seule classe ($\Rightarrow$ test de la variance)}
\ncline[linecolor=gray]{<-}{A}{B}

Influence du bruit
Ajout d'un bruit gaussien sur l'image $\Rightarrow$ convolution de l'histogramme de l'image par une gaussienne.
  \includegraphics[width=10cm]{seuillage_bruit}
  \imgref{Gonzalez $\&$ Woods}
Solutions possibles :
* Débruiter l'image initiale (filtre gaussien, filtre moyenneur, méthode de débruitage, ...)
* Filtrer l'image seuillée (opérateurs morphologiques, filtre médian, ...)
  \only<2>{\rput[c](.5\linewidth,-2){\includegraphics[width=8cm]{vincent72}}}
* Incorporer de l'information spatiale dans la méthode de segmentation.
  \includegraphics[width=10cm]{seuillage_filtre_median} -->
</div>
</div>
<div class="section" id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h2>
<p>Le seuillage s’applique sur une image monochrome, pour laquelle il est facile de définir un seuil à partir des modes de l’histogramme.
Mais pour segmenter une image multibande (par exemple une image couleur),
il n’est pas possible de s’appuyer sur l’histogramme de l’image car il est possède maintenant plusieurs dimensions.
Un pixel d’une image à <span class="math notranslate nohighlight">\(B\)</span> bandes est ainsi représenté par un vecteur à valeurs dans <span class="math notranslate nohighlight">\(\mathbb{R}^B\)</span>.</p>
<div class="figure align-default" id="f-segmentation-clasification">
<a class="reference internal image-reference" href="_images/segmentation-classification.png"><img alt="_images/segmentation-classification.png" src="_images/segmentation-classification.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 59 </span><span class="caption-text">Représentation dans <span class="math notranslate nohighlight">\(\mathbb{R}^B\)</span> d’un pixel d’une image.</span><a class="headerlink" href="#f-segmentation-clasification" title="Permalink to this image">¶</a></p>
</div>
<p>Le principe des méthodes de classification (ou plus exactement de coalescence, en anglais : <em>clustering</em>)
est de regrouper les pixels en groupes homogènes.</p>
<div class="section" id="algorithme-des-k-moyennes">
<h3>Algorithme des k-moyennes<a class="headerlink" href="#algorithme-des-k-moyennes" title="Permalink to this headline">¶</a></h3>
<p>L’algorithme des k-moyennes (<em>k-means</em>) (Steinhaus 1957, MacQueen 1967)
est une méthode itérative qui affecte chaque point de l’espace <span class="math notranslate nohighlight">\(\mathbb{R}^B\)</span> (chaque pixel, donc)
à un groupe particulier (<em>clusters</em>).
Le nombre <span class="math notranslate nohighlight">\(K\)</span> de groupes est choisi par l’utilisateur.</p>
<p>L’algorithme est le suivant :</p>
<ul class="simple">
<li><p>Initialisation aléatoire de <span class="math notranslate nohighlight">\(K\)</span> centroïdes</p></li>
<li><p>Répéter tant que les centroïdes varient :</p>
<ul>
<li><p>Pour chaque point :</p>
<ul>
<li><p>Calcul des distances du point à tous les centroïdes</p></li>
<li><p>Affectation du point au groupe le plus proche</p></li>
</ul>
</li>
<li><p>Calcul du centroïde de chacun des groupes</p></li>
</ul>
</li>
</ul>
<p>La <a class="reference internal" href="#f-segmentation-kmeans-algo"><span class="std std-numref">Fig. 60</span></a> illustre cet algorithme,
dans le cas simple d’une image à deux bandes (espace à deux dimensions)
à segmenter en <span class="math notranslate nohighlight">\(K=2\)</span> classes (deux couleurs, ici rouge et vert).</p>
<div class="figure align-default" id="f-segmentation-kmeans-algo">
<a class="reference internal image-reference" href="_images/segmentation-kmeans-algo.gif"><img alt="_images/segmentation-kmeans-algo.gif" src="_images/segmentation-kmeans-algo.gif" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 60 </span><span class="caption-text">Illustration de l’algorithme des k-moyennes.</span><a class="headerlink" href="#f-segmentation-kmeans-algo" title="Permalink to this image">¶</a></p>
</div>
<p>La <a class="reference internal" href="#f-segmentation-kmeans-result"><span class="std std-numref">Fig. 61</span></a> donne le résultat de l’algorithme des k-means sur une image.</p>
<div class="figure align-default" id="f-segmentation-kmeans-result">
<a class="reference internal image-reference" href="_images/segmentation-kmeans-result.png"><img alt="_images/segmentation-kmeans-result.png" src="_images/segmentation-kmeans-result.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 61 </span><span class="caption-text">Exemple d’application de l’algorithme des k-means sur l’image de gauche (au centre : <span class="math notranslate nohighlight">\(K=2\)</span> classes, à droite : <span class="math notranslate nohighlight">\(K=4\)</span> classes).</span><a class="headerlink" href="#f-segmentation-kmeans-result" title="Permalink to this image">¶</a></p>
</div>
<p>Les avantages de l’algorithme des k-means sont :</p>
<ul>
<li><p>méthode simple</p></li>
<li><p>implémentation facile</p></li>
<li><p>méthode généralement rapide</p></li>
<li><p>classes de variance conditionnelle minimale</p></li>
<li><p>fonctionne correctement lorsque les clusters sont sphériques</p>
<a class="reference internal image-reference" href="_images/vinc51-1.png"><img alt="_images/vinc51-1.png" src="_images/vinc51-1.png" style="height: 70px;" /></a>
</li>
</ul>
<p>Les inconvénients de l’algorithme des k-means sont :</p>
<ul>
<li><p>nécessite de connaître le nombre de classes</p></li>
<li><p>sensible aux minima locaux, donc à l’initialisation</p></li>
<li><p>peut être lent en grande dimension</p></li>
<li><p>échoue pour des structures non sphériques</p>
<a class="reference internal image-reference" href="_images/vinc51-2.png"><img alt="_images/vinc51-2.png" src="_images/vinc51-2.png" style="height: 70px;" /></a>
</li>
<li><p>sensible aux valeurs aberrantes</p>
<a class="reference internal image-reference" href="_images/vinc51-3.png"><img alt="_images/vinc51-3.png" src="_images/vinc51-3.png" style="height: 70px;" /></a>
</li>
</ul>
<!-- ### Modèles paramétriques


L'histogramme de l'image est modélisé par un mélange de lois \eng{mixture model} :
on dispose d'un modèle paramétrique représentatif des classes présentes dans l'image.

  \includegraphics[width=10cm]{vincent52}

* Lois : souvent gaussiennes \eng{GMM : Gaussian mixture model}.
* Extension possible à plusieurs dimensions

Deux étapes :
\begin{enumerate}
* Estimation des paramètres des lois
  {\color{gray}Poids $\Pi_k$, moyennes $\mu_k$, écart-types $\sigma_k$}
    \includegraphics[width=6cm]{vincent54}
* Classification
  {\color{gray}Associer à chaque intensité la classe la plus représentative}
\end{enumerate}

\paragraph{{\color{unistra}$\blacksquare$\hspace*{-.6em}\scriptsize\sf\raisebox{.5mm}{\color{white}1}}\; Estimation}

$$
  \forall i,\qquad
  p(h(i)|\theta) = \sum_{k=1}^K \frac{\Pi_k}{\sqrt{2\pi\sigma_k^2}} \exp\left(-\frac{(h(i)-\mu_k)^2}{2\sigma_k^2}\right)
$$

où $K$ est le nombre de classes
et $\theta$ regroupe les paramètres inconnus des lois :
$\theta=[\Pi_1,...,\Pi_K,\mu_1,...,\mu_K,\sigma_1,...,\sigma_K]$.

Estimation des paramètres au sens du maximum de vraisemblance :

$$
  \hat{\theta}^\text{MV} = \arg \max_{\theta} \prod_i p(h(i)|\theta)
$$

Méthode de résolution : algorithme EM, algorithmes MCMC, ...

\paragraph{{\color{unistra}$\blacksquare$\hspace*{-.6em}\scriptsize\sf\raisebox{.5mm}{\color{white}2}}\; Classification}

  \includegraphics[width=6cm]{vincent54}

Chaque pixel est affecté à la classe dont il maximise la loi :

$$
  f_\text{seg}(m,n) = \arg \max_{k\in\{1,...,K\}}
    \frac{\Pi_k}{\sqrt{2\pi\sigma_k^2}} \exp\left(-\frac{(f(m,n)-\mu_k)^2}{2\sigma_k^2}\right)
$$

\parbox{.45\textwidth}{\paragraph{k-moyennes}}
\parbox{.45\textwidth}{\paragraph{Mélange de gaussiennes}}

\parbox{.45\textwidth}{Estimation uniquement des $\mu_k$}
\parbox{.45\textwidth}{Estimation des $\mu_k$ et $\sigma_k$}

\parbox{.45\textwidth}{Sensible à l'initialisation}
\parbox{.45\textwidth}{Sensible à l'initialisation}

\parbox{.45\textwidth}{Sensible aux minima locaux}
\parbox{.45\textwidth}{Sensible aux minima locaux}

\parbox{.45\textwidth}{Nécessite de connaître le nombre de classes}
\parbox{.45\textwidth}{Nécessite de connaître le nombre de classes}

\parbox{.45\textwidth}{\centering\includegraphics[width=4cm]{vincent58-kmeans}}
\parbox{.45\textwidth}{\centering\includegraphics[width=4cm]{vincent58-gmm}} -->
</div>
</div>
<div class="section" id="region-based-methods">
<h2>Region-based methods<a class="headerlink" href="#region-based-methods" title="Permalink to this headline">¶</a></h2>
<p>La limite fondamentale des méthodes précédentes est
de ne pas prendre en compte l’information de voisinage :
seule l’information de distribution des intensités est utilisée.</p>
<p>À l’inverse, les méthodes basées région sont capables d’agréger des pixels spatialement proches <em>et</em> ayant des intensités similaires.
Nous allons voir deux méthodes basées régions :</p>
<ul class="simple">
<li><p>la croissance de région</p></li>
<li><p>la méthode de décomposition/fusion</p></li>
</ul>
<div class="section" id="croissance-de-region">
<h3>Croissance de région<a class="headerlink" href="#croissance-de-region" title="Permalink to this headline">¶</a></h3>
<p>Le principe de la croissance de région (<em>region growing</em>) est, à partir d’un pixel initial (appelé « germe »),
d’étendre la région en y ajoutant les pixels du voisinage qui satisfont le critère d’homogénéité,
comme l’illustre la <a class="reference internal" href="#f-segmentation-regiongrowing"><span class="std std-numref">Fig. 62</span></a>.</p>
<div class="figure align-default" id="f-segmentation-regiongrowing">
<a class="reference internal image-reference" href="_images/segmentation-regiongrowing.png"><img alt="_images/segmentation-regiongrowing.png" src="_images/segmentation-regiongrowing.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 62 </span><span class="caption-text">Illustration de la croissance de région (le germe est indiqué par la croix rouge).</span><a class="headerlink" href="#f-segmentation-regiongrowing" title="Permalink to this image">¶</a></p>
</div>
<p>Le choix du germe peut se faire manuellement ou automatiquement
(par exemple en choisissant au hasard un pixel en dehors des zones de fort contraste).</p>
<p>Le critère de similarité est le suivant :
si un pixel <span class="math notranslate nohighlight">\(f(m,n)\)</span> et une région <span class="math notranslate nohighlight">\(R\)</span> sont suffisamment similaires, alors ils sont fusionnés ; sinon une nouvelle région est créée.
On peut utiliser par exemple le critère</p>
<div class="math notranslate nohighlight">
\[
  \left| f(m,n) - \mu_R \right| &lt; T \sigma_R
\]</div>
<p>Ainsi, si le paramètre <span class="math notranslate nohighlight">\(T\)</span> est élevé, il sera facile d’agréger des nouveaux pixels à la région.
Au contraire, si <span class="math notranslate nohighlight">\(T\)</span> faible alors il sera plus difficile d’agréger des nouveaux pixels à la région.</p>
<!-- Choix de la connexité : 4-voisinage ou 8-voisinage. -->
<!-- * $R$ : région segmentée, initialisée au germe
* $S$ : pixels à tester, initialisé au voisinage du germe (file FIFO : \emph{first in, first out})
Algorithme :
  \setlength{\fboxsep}{3mm}
  \colorbox{algobg}{\parbox{.9\textwidth}{
  tant que $S$ n'est pas vide :
  \albar $p$ est le premier pixel de la liste $S$
  \albar $p$ est retiré de $S$
  \albar si $p$ est homogène avec $R$ :
  \albar\albar ajout à $R$ de $p$
  \albar\albar ajout à $S$ des pixels du voisinage de $p$ qui ne sont pas dans
  \albar\albar\qquad $R$ et qui ne sont pas incompatibles.
  \albar sinon :
  \albar\albar $p$ est marqué comme incompatible.
 -->
<p>La croissance de région ne fournit pas directement une partition de l’image,
mais permet de segmenter une ou plusieurs structures d’intérêt via la sélection de germes adaptés.
Pour segmenter une image en <span class="math notranslate nohighlight">\(K\)</span> classes, il faudra donc <span class="math notranslate nohighlight">\(K\)</span> germes.</p>
<!-- Au moins deux points germes sont nécessaires :
  \imgbox{45mm}{eclairs}{Image originale}\qquad
  \imgbox{45mm}{eclair1}{Image segmentée} -->
<!-- Quelle segmentation est obtenue avec la plus grande valeur de $T$ ?
    \imgbox{40mm}{eclair1}{\only<1>{A}\only<2>{$T$ petit}\phantom{gT}}\qquad
    \imgbox{40mm}{eclair3}{\only<1>{B}\only<2>{$T$ grand}\phantom{gT}}% -->
<!-- % TODO : ??? \textcolor{red!70}{Rq : en cas d'utilisation de statistique globale pour le test d'homogénéité, l'ordre de traitement des pixels peut influencer le résultat final.} -->
</div>
<div class="section" id="decomposition-fusion">
<h3>Décomposition/fusion<a class="headerlink" href="#decomposition-fusion" title="Permalink to this headline">¶</a></h3>
<p>La méthode de décomposition/fusion (<em>split and merge</em>) fonctionne en deux étapes :</p>
<ol class="simple">
<li><p>d’abord, l’image est décomposée successivement en régions
si elles ne satisfont pas le critère d’homogénéité.
Cela permet d’aboutir à une première partition de l’image ;</p></li>
<li><p>ensuite, les régions obtenues sont fusionnées si elles sont adjacentes et qu’elles vérifient le critère d’homogénéité.</p></li>
</ol>
<!-- \onslide<4->{Les représentations en arbre et par graphe permettent une représentation haut niveau de l'image.} -->
<p><strong>Décomposition</strong></p>
<p>La décomposition est une procédure itérative.
Au départ, il n’y a qu’une seule région qui correspond à l’image toute entière.
À chaque itération, les régions qui ne vérifient pas le critère d’homogénéité sont divisées en quatre nouvelles régions de taille identique.
La procédure s’arrête lorsque les régions sont toutes homogènes ;
au pire, les régions les plus petites sont ainsi des pixels uniques.</p>
<p>On peut utiliser une représentation en quad-arbre (<em>quad-tree</em>) de cette décomposition :
c’est une arborescence dont chaque nœud représente une région et possède quatre fils,
la racine représente l’image entière.</p>
<div class="figure align-default" id="f-segmentation-split-merge-quadtree">
<a class="reference internal image-reference" href="_images/segmentation-split-merge-quadtree.gif"><img alt="_images/segmentation-split-merge-quadtree.gif" src="_images/segmentation-split-merge-quadtree.gif" style="height: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 63 </span><span class="caption-text">Illustration de la décomposition avec représentation en quad-arbre.</span><a class="headerlink" href="#f-segmentation-split-merge-quadtree" title="Permalink to this image">¶</a></p>
</div>
<p>Finalement, la méthode de décomposition par quad-arbre fait apparaître des régions carrées sur l’image segmentée.
Le problème majeur de cette décomposition provient de la rigidité des divisions réalisées sur l’image,
mais au moins cela fournit une partition initiale de l’image.</p>
<p><strong>Fusion</strong></p>
<p>La partition de l’image obtenue avec la la représentation en quad-arbre
peut être vue comme un graphe d’adjacence (RAG : <em>region adjacency graph</em>).
C’est une nouvelle représentation, sous forme de graphe, dont :</p>
<ul class="simple">
<li><p>les nœuds correspondent à une région de l’image,</p></li>
<li><p>les arêtes relient les nœuds correspondants à deux régions adjacentes (ayant une frontière commune).
La <a class="reference internal" href="#f-segmentation-rag"><span class="std std-numref">Fig. 64</span></a> donne un exemple de tel graphe.</p></li>
</ul>
<div class="figure align-default" id="f-segmentation-rag">
<a class="reference internal image-reference" href="_images/vincent88.png"><img alt="_images/vincent88.png" src="_images/vincent88.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 64 </span><span class="caption-text">Une image segmentée et sa représentation sous forme de graphe d’adjacence.</span><a class="headerlink" href="#f-segmentation-rag" title="Permalink to this image">¶</a></p>
</div>
<p>Donc, à partir de ce graphe d’adjacence, les nœuds <span class="math notranslate nohighlight">\(R_1\)</span> et <span class="math notranslate nohighlight">\(R_2\)</span> voisins et dont le critère de similarité sur <span class="math notranslate nohighlight">\(R_1 \cup R_2\)</span> est respecté
sont fusionnés (cf. <a class="reference internal" href="#f-segmentation-split-merge-rag"><span class="std std-numref">Fig. 65</span></a>).</p>
<div class="figure align-default" id="f-segmentation-split-merge-rag">
<a class="reference internal image-reference" href="_images/segmentation-split-merge-rag.gif"><img alt="_images/segmentation-split-merge-rag.gif" src="_images/segmentation-split-merge-rag.gif" style="height: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 65 </span><span class="caption-text">Illustration de la fusion avec représentation en graphe d’adjacence.</span><a class="headerlink" href="#f-segmentation-split-merge-rag" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="watershed">
<h2>Watershed<a class="headerlink" href="#watershed" title="Permalink to this headline">¶</a></h2>
<p>La ligne de partage des eaux (<em>watershed</em>) considère l’image comme un carte topographique où :</p>
<ul class="simple">
<li><p>les régions de la segmentation sont les vallées</p></li>
<li><p>les frontières entre régions sont les crêtes</p></li>
</ul>
<p>Ainsi la <a class="reference internal" href="#f-segmentation-watershed-moon"><span class="std std-numref">Fig. 66</span></a> montre, pour une image de la Lune, ce que devrait être la carte topographique correspondante.
Cette carte est en fait la vue 3D de la norme du gradient de l’image.</p>
<div class="figure align-default" id="f-segmentation-watershed-moon">
<a class="reference internal image-reference" href="_images/segmentation-watershed-moon.png"><img alt="_images/segmentation-watershed-moon.png" src="_images/segmentation-watershed-moon.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 66 </span><span class="caption-text">Une image et son gradient (vu comme une image et comme un signal 3D, faisant apparaître le relief).</span><a class="headerlink" href="#f-segmentation-watershed-moon" title="Permalink to this image">¶</a></p>
</div>
<p>Le principe de la ligne de partage des eaux est donc :</p>
<ol class="simple">
<li><p>de construire la carte d’élévation,</p></li>
<li><p>de remplir progressivement d’eau chaque bassin versant : l’eau apparaît tout en bas du relief,</p></li>
<li><p>de faire monter le niveau de l’eau,</p></li>
<li><p>lorsque deux bassins se rejoignent, la ligne de partage des eaux est marquée comme frontière.</p></li>
</ol>
<p>La <a class="reference internal" href="#f-segmentation-watershed-algo"><span class="std std-numref">Fig. 67</span></a> schématise cet algorithme sur une coupe de l’image.</p>
<div class="figure align-default" id="f-segmentation-watershed-algo">
<a class="reference internal image-reference" href="_images/segmentation-watershed-algo.gif"><img alt="_images/segmentation-watershed-algo.gif" src="_images/segmentation-watershed-algo.gif" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 67 </span><span class="caption-text">Schématisation de l’algorithme de ligne de partage des eaux.</span><a class="headerlink" href="#f-segmentation-watershed-algo" title="Permalink to this image">¶</a></p>
</div>
<!-- Algorithme :
 \setlength{\fboxsep}{3mm}
 \colorbox{algobg}{\parbox{.9\textwidth}{
  Calculer le gradient (ou le Laplacien) de l'image.
  Les pixels ayant l'intensité la plus faible forment les bassins \phantom{\albar}\quad versants initiaux.
  Pour chaque niveau d'intensité $i$ :
  \albar Pour chaque groupe de pixels d'intensité $i$ :\\
  \albar\albar Si adjacent à exactement une région existante :\\\albar\albar\quad ajouter ces pixels dans cette région.\\
  \albar\albar Si adjacent à plusieurs régions simultanément :\\\albar\albar\quad marquer comme ligne de partage des eaux.
  \albar\albar Sinon, commencer une nouvelle région. -->
<p>Une des limites de cette méthode apparaît lorsqu’il y a beaucoup de minima locaux dans le gradient.
Dit autrement, il y a trop de bassins versants très petits, qui sont alors autant de régions dans la segmentation.
Pour limiter ce nombre, on peut :</p>
<ul class="simple">
<li><p>lisser (avec un filtre passe-bas) le gradient avant d’appliquer l’algorithme,</p></li>
<li><p>choisir manuellement les bassins versants d’intérêt avec des marqueurs,</p></li>
<li><p>ou fusionner les minima locaux.</p></li>
</ul>
<!-- ## Snakes

Contours actifs

Principe : à partir d'un contour initial proche de l'objet à segmenter,
le contour évolue de manière itérative et cherche à converger
vers les zones de fort gradient (= contour) sous certaines contraintes (forme, longueur, etc.).

Le contour est modélisé par un ensemble de points (x_i,y_i)
qui se déplacent légèrement à chaque itération pour déformer le contour.

  \includegraphics[width=7cm]{vincent117-1}

Le contour cherche à minimiser une énergie (ou fonction coût)
qui mesure la qualité de la segmentation :

  E_\text{totale} = E_\text{interne} + \lambda E_\text{externe}

* Énergie interne : encourage certaines configurations de forme
  (régularité, élasticité, a priori de forme, ...)
* Énergie externe : encourage le modèle à converger vers les contours des objets
  (zones de fort gradient)

% Différents types d'énergie interne :
%   \includegraphics[width=8cm]{vincent115} -->
</div>
<div class="section" id="how-to-evaluate-the-segmentation">
<h2>How to evaluate the segmentation?<a class="headerlink" href="#how-to-evaluate-the-segmentation" title="Permalink to this headline">¶</a></h2>
<p>Ce chapitre a présenté les principales méthodes de segmentation, mais il en existe beaucoup d’autres !
Il n’existe pas une méthode de segmentation meilleure que tous les autres, dans tous les cas : le résultat dépend entre autre de l’image elle-même.
Par conséquent, il est intéressant d’évaluer, pour le type d’image que l’on traite, la qualité de la segmentation.
Pour cela, on peut utiliser différents critères, définis ci-après.
En plus de l’image à segmenter, on a également besoin du résultat attendu, qu’on appelle « vérité terrain » (<em>ground truth</em>).</p>
<p>Imaginons, dans le cas d’une segmentation binaire,
que la vérité terrain et la segmentation obtenue sont les images de la <a class="reference internal" href="#f-segmentation-eval-gt-est"><span class="std std-numref">Fig. 68</span></a>.
Chaque image possède donc deux zones : l’objet segmenté (représenté en blanc) et le fond (en noir).
Alors, on peut définir quatre types de zones (cf. <a class="reference internal" href="#f-segmentation-eval-zones"><span class="std std-numref">Fig. 69</span></a>) :</p>
<ul class="simple">
<li><p>les vrais positifs (VP) représentent les pixels considérés comme étant dans l’objet et étant réellement dans l’objet,</p></li>
<li><p>à l’inverse, les vrais négatifs (VN) sont les pixels hors de l’objet à la fois dans la segmentation et la vérité terrain,</p></li>
<li><p>les faux positif (FP) sont les pixels considérés par la segmentation dans l’objet, mais qui en vrai n’en font pas partie,</p></li>
<li><p>enfin, les faux négatif (FN) sont les pixels de l’objet que la segmentation a classé en dehors.</p></li>
</ul>
<div class="figure align-default" id="f-segmentation-eval-gt-est">
<a class="reference internal image-reference" href="_images/segmentation-eval-gt-est.png"><img alt="_images/segmentation-eval-gt-est.png" src="_images/segmentation-eval-gt-est.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 68 </span><span class="caption-text">Vérité terrain <span class="math notranslate nohighlight">\(f^*\)</span> (à gauche) et segmentation obtenue <span class="math notranslate nohighlight">\(f\)</span> (à droite).</span><a class="headerlink" href="#f-segmentation-eval-gt-est" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="f-segmentation-eval-zones">
<a class="reference internal image-reference" href="_images/eval-zones.png"><img alt="_images/eval-zones.png" src="_images/eval-zones.png" style="height: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 69 </span><span class="caption-text">Définition des vrais positifs (VP), faux positifs (FP), vrais négatifs (VN) et faux négatifs (FN).</span><a class="headerlink" href="#f-segmentation-eval-zones" title="Permalink to this image">¶</a></p>
</div>
<p>À partir de ces quatre quantités, on peut utiliser l’un ou l’autre des critères suivants :</p>
<ul>
<li><p>la sensibilité :</p>
<div class="math notranslate nohighlight">
\[
  \frac{\text{VP}}{\text{VP}+\text{FN}},
  \]</div>
</li>
<li><p>la spécificité :</p>
<div class="math notranslate nohighlight">
\[
  \frac{\text{VN}}{\text{VN}+\text{FP}},
  \]</div>
</li>
<li><p>le coefficient de Dice :</p>
<div class="math notranslate nohighlight">
\[
  \frac{2\,\text{VP}}{2\,\text{VP}+\text{FP}+\text{FN}} = \frac{2\,|f\, \cap f\,^*|}{|f\,| + |f\,^*|},
  \]</div>
</li>
<li><p>le coefficient de Jaccard :</p>
<div class="math notranslate nohighlight">
\[
  \frac{\text{VP}}{\text{VP}+\text{FP}+\text{FN}} = \frac{|f\, \cap f\,^*|}{|f\, \cup f\,^*|}.
  \]</div>
</li>
</ul>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>En conclusion, nous avons vu que la segmentation consiste à diviser l’image en plusieurs régions homogènes.
L’homogénéité d’une région est basée sur la couleur, la texture, les contours…
Les méthodes de segmentation sont très diverses, et nous n’en avons vu que quelques unes.
Parmi les autres méthodes existantes, citons les contours actifs (<em>snakes</em>),
les ensembles de niveaux (<em>level sets</em>), les modèles markoviens, etc.</p>
<!--   \bibitem[Achanta  et coll. 2012]{Achanta12}
  R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Süsstrunk,
  \og{}SLIC Superpixels Compared to State-of-the-art Superpixel Methods \fg{},
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 34(11), p. 2274--2282, 2012.

  \bibitem[Fukunaga \& Hostetler 1975]{Fukunaga75}
  K. Fukunaga, L.D. Hostetler,
  \og{}The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition\fg{},
  \emph{IEEE Transactions on Information Theory}, 21(1) p. 32--40, 1975.

  \bibitem[MacQueen 1967]{MacQueen67}
  J.B. MacQueen,
  \og{}Some Methods for classification and Analysis of Multivariate Observations\fg{},
  5th Berkeley Symposium on Mathematical Statistics and Probability., p. 281--297, 1967.

  \bibitem[Otsu 1979]{Otsu79}
  N. Otsu,
  \og{}A threshold selection method from gray-level histograms\fg{},
  \emph{ IEEE Transactions on Systems, Man, and Cybernetics} 9(1) p. 62--66, 1979.

  \bibitem[Sezguin et Sankur 2004]{Sezgin04}
  M. Sezgin, B. Sankur,
  \og{}Survey over image thresholding techniques and quantitative performance evaluation\fg{},
  \emph{Journal of Electronic Imaging} 13(1), p. 146--165, 2004.

  \bibitem[Steinhaus 1957]{Steinhaus57}
  H. Steinhaus,
  \og{}Sur la division des corps matériels en parties\fg{}
  \emph{Bulletin de l'Académie Polonaise des Sciences}, 4(12) p. 801--804, 1957.
 -->
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="registration.html" title="previous page">Registration</a>
    <a class='right-next' id="next-link" href="deconvolution.html" title="next page">Deconvolution</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Vincent Mazet (University of Strasbourg, France)<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            Fundamental Tools for Image Processing &mdash; Vincent Mazet (Université de Strasbourg), 2020 &mdash; <a href="license.html">CC BY-NC 4.0</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>


<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Edges detection &#8212; Fundamental Tools for Image Processing</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jbvinc.css" />
    <link rel="stylesheet" type="text/css" href="../_static/.ipynb_checkpoints/jbvinc-checkpoint.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Corner detection" href="corners.html" />
    <link rel="prev" title="Introduction" href="intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Fundamental Tools for Image Processing</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../preface.html">
   Preface
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Basics
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../definition.html">
   What is a Digital Image?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../operations.html">
   Arithmetic Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../histogram.html">
   Histogram
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../convolution.html">
   Convolution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fourier.html">
   Fourier Transform
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Compression
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../compression.html">
   Compression
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Mathematical Morphology
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../mm.html">
   Mathematical Morphology
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Registration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../interpolation.html">
   Interpolation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../registration.html">
   Registration
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Segmentation
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../segmentation.html">
   Segmentation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Restoration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../denoising.html">
   Denoising
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deconvolution.html">
   Deconvolution
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Feature Detection
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Edges detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="corners.html">
   Corner detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lines.html">
   Line detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="outro.html">
   Conclusion
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  In-Class Sessions
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../tp1.html">
   07/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tp2.html">
   14/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tp3.html">
   21/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tp4.html">
   04/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tp5.html">
   18/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tp6.html">
   25/11/2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Corrections
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp1-code.html">
   07/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp2-code.html">
   14/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp3-code.html">
   21/10/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp4-code.html">
   04/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp5-code.html">
   18/11/2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../labs/tp6-code.html">
   25/11/2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://moodle3.unistra.fr/course/view.php?id=13708">
   Moodle
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python.html">
   Installing and Using Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../biblio.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../license.html">
   License
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/feature/edges.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interet-de-la-derivee">
   Intérêt de la dérivée
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#operateurs-du-gradient">
   Opérateurs du gradient
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#impact-du-bruit-sur-la-detection">
     Impact du bruit sur la détection
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methodes-avancees">
   Méthodes avancées
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detecteur-de-marr-hildreth">
     Détecteur de Marr-Hildreth
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detecteur-de-canny">
     Détecteur de Canny
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparaison">
     Comparaison
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="edges-detection">
<h1>Edges detection<a class="headerlink" href="#edges-detection" title="Permalink to this headline">¶</a></h1>
<p>Les contours (<em>edges</em>) dans une image sont les zones qui délimitent les objets observés.
Détecter des contours est donc utile pour identifier les objets dans une image, ce qui peut permettre par exemple de mesurer leur taille.</p>
<div class="figure align-default" id="f-feature-edges-example">
<a class="reference internal image-reference" href="../_images/edge-example.png"><img alt="../_images/edge-example.png" src="../_images/edge-example.png" style="width: 250px;" /></a>
</div>
<div class="section" id="interet-de-la-derivee">
<h2>Intérêt de la dérivée<a class="headerlink" href="#interet-de-la-derivee" title="Permalink to this headline">¶</a></h2>
<p>Les contours sont caractérisés par une variation rapide de l’intensité des pixels.
La <a class="reference internal" href="#f-feature-edges-profile"><span class="std std-numref">Fig. 88</span></a> représente le profil de luminosité selon une ligne horizontale dans l’image.
On voit clairement que le contour du chapeau se caractérise par une croissante brutale de la luminosité des pixels.</p>
<div class="figure align-default" id="f-feature-edges-profile">
<div class="cell_output docutils container">
<img alt="../_images/edges_3_1.png" src="../_images/edges_3_1.png" />
</div>
</div>
<p>En conséquence, la dérivée est un outil efficace pour mettre en évidence les contours d’une image.
la présence d’un contour peut être détectée en analysant l’amplitude de la dérivée 1<sup>re</sup>
du profil d’intensité perpendiculairement au contour.
On peut également détecter un contour en déterminant le passage à zéro de la dérivée 2<sup>e</sup>.</p>
<div class="figure align-default" id="f-feature-edges-derivatives">
<a class="reference internal image-reference" href="../_images/derivatives.png"><img alt="../_images/derivatives.png" src="../_images/derivatives.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 89 </span><span class="caption-text">De gauche à droite : une image simple, son profil de luminosité suivant l’axe horizontal,
la dérivée 1<sup>re</sup> et la dérivée 2<sup>e</sup>.</span><a class="headerlink" href="#f-feature-edges-derivatives" title="Permalink to this image">¶</a></p>
</div>
<p>Comme une image dépend de deux dimensions, les dérivées sont à calculer selon les deux axes.
Par exemple, la dérivée 1<sup>re</sup> d’une image est constituée des termes
<span class="math notranslate nohighlight">\(\frac{\partial f(x,y)}{\partial x}\)</span> et <span class="math notranslate nohighlight">\(\frac{\partial f(x,y)}{\partial y}\)</span>.
Comme en plus une image est numérique, les dérivées sont calculées à l’aide des différences discrètes.
Par exemple :</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial f(x,y)}{\partial x} = f(x+1,y) - f(x,y).
\]</div>
<p>Ainsi, en notant <span class="math notranslate nohighlight">\(f\)</span> l’image :</p>
<!-- (image représentant le gradient, GW p.729) -->
<ul>
<li><p>la dérivée 1<sup>re</sup>, appelée « gradient » est définie par :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \nabla f =
  \begin{pmatrix}
    f(x+1,y) - f(x,y) \\ f(x,y+1) - f(x,y)
  \end{pmatrix}
  \end{split}\]</div>
</li>
<li><p>la dérivée 2<sup>e</sup>, appelée « laplacien » est définie par :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \Delta f =
  \begin{pmatrix}
    f(x+1,y) - 2f(x,y) + f(x-1,y) \\ f(x,y+1) - 2f(x,y) + f(x,y-1)
  \end{pmatrix}
  \end{split}\]</div>
</li>
</ul>
</div>
<div class="section" id="operateurs-du-gradient">
<h2>Opérateurs du gradient<a class="headerlink" href="#operateurs-du-gradient" title="Permalink to this headline">¶</a></h2>
<p>Les opérateurs de gradient sont des méthodes très simples de détection de contours.
Elles utilisent la dérivée 1<sup>re</sup> et peuvent se calculer à l’aide d’une convolution.</p>
<p>La dérivée 1<sup>re</sup> selon l’axe <span class="math notranslate nohighlight">\(x\)</span> d’une image <span class="math notranslate nohighlight">\(f\)</span> peut s’écrire comme un produit de convolution :</p>
<div class="math notranslate nohighlight">
\[
f(x+1,y) - f(x,y) = \sum_m \sum_n h_x(m,n) f(x-m,y-n)
\]</div>
<p>où <span class="math notranslate nohighlight">\(h_x\)</span> est un noyau de convolution tel que :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{cases}
  h_x(0,0) = -1 \\
  h_x(-1,0) = +1 \\
  h_x(m,n) = 0 \quad\text{ailleurs}
\end{cases}
\end{split}\]</div>
<p>Ainsi, le noyau <span class="math notranslate nohighlight">\(h_x\)</span> s’écrit :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
h_x =
\begin{pmatrix}
  0 &amp; +1 \\
  0 &amp; -1 \\
\end{pmatrix}
\end{split}\]</div>
<p>De même, la dérivée 1<sup>re</sup> selon l’axe <span class="math notranslate nohighlight">\(y\)</span> s’écrit comme la convolution de <span class="math notranslate nohighlight">\(f\)</span> avec un noyau <span class="math notranslate nohighlight">\(h_y\)</span> tel que :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
h_y =
\begin{pmatrix}
  0 &amp;  0 \\
  +1 &amp; -1 \\
\end{pmatrix}
\end{split}\]</div>
<p>Le fait d’introduire une colonne de 0 dans <span class="math notranslate nohighlight">\(h_x\)</span> et une ligne de 0 dans <span class="math notranslate nohighlight">\(h_y\)</span> permet d’avoir des noyaux de même taille.</p>
<p>Ces deux noyaux constituent les filtres de Roberts [Roberts 1965] :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  h_x=
  \begin{pmatrix}
    0 &amp; +1 \\
    0 &amp; -1 \\
  \end{pmatrix}
  \quad
  h_y=
  \begin{pmatrix}
    0 &amp; 0 \\
    +1 &amp; -1 \\
  \end{pmatrix}
\end{split}\]</div>
<p>Une variante de ces filtres sont les filtres de Prewitt [Prewitt 1970] qui permettent de centrer les filtres de Roberts :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  h_x=
  \begin{pmatrix}
    +1 &amp; +1 &amp; +1 \\
    0 &amp; 0 &amp; 0 \\
    -1 &amp; -1 &amp; -1 \\
  \end{pmatrix}
  \quad
  h_y=
  \begin{pmatrix}
    +1 &amp; 0 &amp; -1 \\
    +1 &amp; 0 &amp; -1 \\
    +1 &amp; 0 &amp; -1 \\
  \end{pmatrix}
\end{split}\]</div>
<p>Enfin, les filtres de Sobel [Sobel 1968] sont une version lissée du filtre de Prewitt
(les coefficients reproduisent une convolution par un filtre gaussien,
qui tend à jouer le rôle d’un filtre moyenneur pour atténuer le bruit) :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  h_x=
  \begin{pmatrix}
    +1 &amp; +2 &amp; +1 \\
    0 &amp; 0 &amp; 0 \\
    -1 &amp; -2 &amp; -1 \\
  \end{pmatrix}
  \quad
  h_y=
  \begin{pmatrix}
    +1 &amp; 0 &amp; -1 \\
    +2 &amp; 0 &amp; -2 \\
    +1 &amp; 0 &amp; -1 \\
  \end{pmatrix}
\end{split}\]</div>
<p>Remarquez que dans tous les cas, la somme des coefficients des filtres est égal à 0.</p>
<p>Dans le cas où l’on cherche des contours orientés à 45°, il existe des variantes diagonalesde ces filtres.</p>
<p>À partir de l’un de ces filtres, on définit également :</p>
<ul>
<li><p>l’amplitude du contour (<em>magnitude</em>) :</p>
<div class="math notranslate nohighlight">
\[
    M = \sqrt{ (h_x*f)^2 + (h_y*f)^2 }
  \]</div>
</li>
<li><p>l’angle (ou la direction) du contour :</p>
<div class="math notranslate nohighlight">
\[
    A = \tan^{-1} \left( \frac{h_y*f}{h_x*f} \right)
  \]</div>
</li>
</ul>
<div class="figure align-default" id="f-feature-edges-sobel">
<a class="reference internal image-reference" href="../_images/feature-1.png"><img alt="../_images/feature-1.png" src="../_images/feature-1.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 90 </span><span class="caption-text">Filtre de Sobel appliqué sur l’image <span class="math notranslate nohighlight">\(f\)</span>.</span><a class="headerlink" href="#f-feature-edges-sobel" title="Permalink to this image">¶</a></p>
</div>
<p>Dans certains cas, on veut simplement détecter les contours les plus importants,
sans forcément avoir besoin de leur amplitude.
Dans ce cas, on peut seuiller l’amplitude pour ne conserver que les grandes valeurs du gradient.</p>
<div class="figure align-default" id="f-feature-edges-sobel-threshold">
<a class="reference internal image-reference" href="../_images/feature-4.png"><img alt="../_images/feature-4.png" src="../_images/feature-4.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-number">Fig. 91 </span><span class="caption-text">Filtre de Sobel appliqué sur l’image <span class="math notranslate nohighlight">\(f\)</span> et le résultat seuillé.</span><a class="headerlink" href="#f-feature-edges-sobel-threshold" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="impact-du-bruit-sur-la-detection">
<h3>Impact du bruit sur la détection<a class="headerlink" href="#impact-du-bruit-sur-la-detection" title="Permalink to this headline">¶</a></h3>
<p>Comme le bruit apporte une variation plus importante de luminosité entre les pixels,
les opérateurs de gradient, qui sont basés sur la dérivée, y seront très sensibles,
comme on le voit sur la <a class="reference internal" href="#f-feature-edges-noise"><span class="std std-numref">Fig. 92</span></a>.
C’est pourquoi il est parfois utile d’introduire un débruitage avant la détection de contour.
Dans la figure <a class="reference internal" href="#f-feature-edges-sobel-noise"><span class="std std-numref">Fig. 93</span></a>, un filtre moyenneur de petite taille est utilisé
avant le filtre de Sobel : le résultat est beaucoup plus propre que sans l’utilisation du filtre moyenneur.</p>
<div class="figure align-default" id="f-feature-edges-noise">
<a class="reference internal image-reference" href="../_images/feature-2.png"><img alt="../_images/feature-2.png" src="../_images/feature-2.png" style="width: 240px;" /></a>
<p class="caption"><span class="caption-number">Fig. 92 </span><span class="caption-text">Résultat du bruit sur la dérivée 1<sup>e</sup>.</span><a class="headerlink" href="#f-feature-edges-noise" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="f-feature-edges-sobel-noise">
<a class="reference internal image-reference" href="../_images/feature-3.png"><img alt="../_images/feature-3.png" src="../_images/feature-3.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-number">Fig. 93 </span><span class="caption-text">Filtre de Sobel sans ou avec débruitage préalable sur une image bruitée.</span><a class="headerlink" href="#f-feature-edges-sobel-noise" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="methodes-avancees">
<h2>Méthodes avancées<a class="headerlink" href="#methodes-avancees" title="Permalink to this headline">¶</a></h2>
<p>Après l’invention des filtres détecteurs de contour, des méthodes plus élaborées ont été développées
pour améliorer la détection en tenant compte du bruit et de la nature des contours :</p>
<ul class="simple">
<li><p>le détecteur de Marr-Hildreth [Marr 1980],</p></li>
<li><p>le détecteur de Canny [Canny 1986].</p></li>
</ul>
<div class="section" id="detecteur-de-marr-hildreth">
<h3>Détecteur de Marr-Hildreth<a class="headerlink" href="#detecteur-de-marr-hildreth" title="Permalink to this headline">¶</a></h3>
<!-- Hypotèses~:
  \item Un contour doit être détecté quelle que soit l'échelle de l'image \\
  \uncover<3>{=> le détecteur doit être réglable pour détecter les contours à une échelle particulière.}
  \item Un contour implique un passage par zéro de la dérivée 2\textsuperscript{e} \\
  \uncover<3>{=> le détecteur doit calculer la dérivée 2\textsuperscript{e}.} -->
<p>Le détecteur de Marr-Hildreth consiste à :</p>
<ol class="simple">
<li><p>appliquer un filtre gaussien <span class="math notranslate nohighlight">\(g\)</span> sur l’image <span class="math notranslate nohighlight">\(f\)</span> pour réduire le bruit,</p></li>
<li><p>calculer le laplacien (dérivée 2<sup>e</sup>) <span class="math notranslate nohighlight">\(\ell\)</span> sur l’image adoucie (cette étape s’implémente avec une convolution),</p></li>
<li><p>déterminer les passages par zéro du résultat.</p></li>
</ol>
<p>Comme <span class="math notranslate nohighlight">\(\ell*(g*f) = (\ell*g) * f\)</span>,
alors les deux premières étapes sont fusionnées en une seule convolution par <span class="math notranslate nohighlight">\(\ell*g\)</span>.
Le filtre gaussien <span class="math notranslate nohighlight">\(g\)</span> a pour expression (<a class="reference internal" href="#f-feature-edges-gaussian"><span class="std std-numref">Fig. 94</span></a>) :</p>
<div class="math notranslate nohighlight">
\[
g(x,y) = \exp\left(-\frac{x^2+y^2}{2\sigma^2}\right),
\]</div>
<p>dont sa dérivée 2<sup>e</sup> s’écrit :</p>
<div class="math notranslate nohighlight">
\[
  \partial^2 g(x,y) = - \left[\frac{x^2+y^2-2\sigma^2}{\sigma^4}\right] \exp\left(-\frac{x^2+y^2}{2\sigma^2}\right)
\]</div>
<p>Cette expression est le laplacien du filtre gaussien <span class="math notranslate nohighlight">\(\ell*g\)</span>,
qui est représenté <a class="reference internal" href="#f-feature-edges-log"><span class="std std-numref">Fig. 95</span></a>.
Il est également appelé LoG (<em>Laplacian of Gaussian</em>) ou chapeau mexicain (pour la ressemblance du profil avec un sombrero).</p>
<div class="figure align-default" id="f-feature-edges-gaussian">
<a class="reference internal image-reference" href="../_images/feature-6.png"><img alt="../_images/feature-6.png" src="../_images/feature-6.png" style="width: 350px;" /></a>
<p class="caption"><span class="caption-number">Fig. 94 </span><span class="caption-text">Filtre gaussien (à gauche : sous forme d’image, à droite : profil suivant un axe).</span><a class="headerlink" href="#f-feature-edges-gaussian" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="f-feature-edges-log">
<a class="reference internal image-reference" href="../_images/feature-7.png"><img alt="../_images/feature-7.png" src="../_images/feature-7.png" style="width: 350px;" /></a>
<p class="caption"><span class="caption-number">Fig. 95 </span><span class="caption-text">Laplacien du filtre gaussien (à gauche : sous forme d’image, à droite : profil suivant un axe).</span><a class="headerlink" href="#f-feature-edges-log" title="Permalink to this image">¶</a></p>
</div>
<!-- Le LoG peut être approximé par une différence de deux gaussiennes. -->
<p>Après avoir convolué l’image par le LoG, une détection de changement de signe dans l’intensité de deux pixels
permet de détecter les passages par zéro.
La <a class="reference internal" href="#f-feature-edges-marr-hildreth"><span class="std std-numref">Fig. 96</span></a> donne un exemple de résultat.
<a class="reference external" href="https://raw.githubusercontent.com/vincmazet/ftip/master/_static/data/feature-9.png"><font color="#fff">ici aussi</font></a></p>
<div class="figure align-default" id="f-feature-edges-marr-hildreth">
<a class="reference internal image-reference" href="../_images/feature-8.png"><img alt="../_images/feature-8.png" src="../_images/feature-8.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-number">Fig. 96 </span><span class="caption-text">Détecteur de Marr-Hildreth.</span><a class="headerlink" href="#f-feature-edges-marr-hildreth" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="detecteur-de-canny">
<h3>Détecteur de Canny<a class="headerlink" href="#detecteur-de-canny" title="Permalink to this headline">¶</a></h3>
<p>Pour Canny, un bon détecteur devrait remplir les objectifs suivants :</p>
<ul class="simple">
<li><p>tous les contours doivent être trouvés,</p></li>
<li><p>il doit y avoir un minimum de réponses parasites,</p></li>
<li><p>les contours correctement localisés (c’est-à-dire que la distance entre un point détecté
et le vrai point du contour doit être la plus faible possible),</p></li>
<li><p>l’épaisseur des contours détectés doit être de 1 pixel
(donc un seul point doit être détecté pour chaque vrai point de contour).</p></li>
</ul>
<p>Canny a exprimé ces objectifs sous forme mathématique
et a proposé des solutions optimales vérifiant ces objectifs.</p>
<p>L’algorithme du détecteur de Canny suit les quatre étapes détaillés ci-après.</p>
<!-- TODO : présenter l'algo avec des illustrations et des schémas -->
<ol>
<li><p>L’image <span class="math notranslate nohighlight">\(f\)</span> est d’abord lissée avec un filtre gaussien pour réduire le bruit.
Une convolution est donc effectuée avec un noyau gaussien <span class="math notranslate nohighlight">\(g\)</span> pour obtenir une image <span class="math notranslate nohighlight">\(z = f * g\)</span>.</p></li>
<li><p>Le gradient de l’image est calculé (amplitude et angle) :</p>
<div class="math notranslate nohighlight">
\[
   M = \sqrt{ (h_x*z)^2 + (h_y*z)^2 }
   \quad\text{et}\quad
   A = \tan^{-1} \left( \frac{h_y*z}{h_x*z} \right)
   \]</div>
</li>
<li><p>Les non-maxima sont supprimés de l’amplitude.
Cela signifie que les contours trop larges dans l’image <span class="math notranslate nohighlight">\(M\)</span> sont remplacés par des contours plus fins.
Pour cela, on applique l’algorithme ci-dessous :</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/feature-10.png"><img alt="../_images/feature-10.png" src="../_images/feature-10.png" style="width: 500px;" /></a>
</div>
</li>
<li><p>Enfin, la dernière étape consiste en un seuillage par hystérésis pour les mauvais contours.
Deux seuils sont donc définis : <span class="math notranslate nohighlight">\(s_\text{haut} &gt; s_\text{bas}\)</span>
et l’algorithme ci-dessous est appliqué :</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/feature-11.png"><img alt="../_images/feature-11.png" src="../_images/feature-11.png" style="width: 500px;" /></a>
</div>
</li>
</ol>
</div>
<div class="section" id="comparaison">
<h3>Comparaison<a class="headerlink" href="#comparaison" title="Permalink to this headline">¶</a></h3>
<p>La <a class="reference internal" href="#f-feature-edges-sobel-marr-hildreth-canny"><span class="std std-numref">Fig. 97</span></a> montre le résulats du filtre de Sobel
et des détecteurs de Marr-Hildreth et Canny sur une image.</p>
<div class="figure align-default" id="f-feature-edges-sobel-marr-hildreth-canny">
<a class="reference internal image-reference" href="../_images/feature-13.png"><img alt="../_images/feature-13.png" src="../_images/feature-13.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 97 </span><span class="caption-text">Résultats pour trois détecteurs de contour.</span><a class="headerlink" href="#f-feature-edges-sobel-marr-hildreth-canny" title="Permalink to this image">¶</a></p>
</div>
<p>Sur la <a class="reference internal" href="#f-feature-edges-marr-hildreth-canny-zoom"><span class="std std-numref">Fig. 98</span></a>, qui compare les détecteurs de Marr-Hildreth et de Canny,
on peut voir que les contours détectés avec le détecteur de Canny sont mieux localisés.</p>
<div class="figure align-default" id="f-feature-edges-marr-hildreth-canny-zoom">
<a class="reference internal image-reference" href="../_images/feature-14.png"><img alt="../_images/feature-14.png" src="../_images/feature-14.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-number">Fig. 98 </span><span class="caption-text">Comparaison entre les détecteurs de Marr-Hildreth et Canny (zoom).
Les contours sont représentés en vert.</span><a class="headerlink" href="#f-feature-edges-marr-hildreth-canny-zoom" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./feature"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">Introduction</a>
    <a class='right-next' id="next-link" href="corners.html" title="next page">Corner detection</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Vincent Mazet (University of Strasbourg, France)<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            Fundamental Tools for Image Processing &mdash; Vincent Mazet (Université de Strasbourg), 2020 &mdash; <a href="license.html">CC BY-NC 4.0</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>